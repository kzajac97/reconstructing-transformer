{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformer for Machine Translation\n",
    "\n",
    "This notebook aims to reproduce transformer model for machine translation from the paper **Attention Is All You Need** using encoder-decoder architecture.\n",
    "The weights are used from HuggingFace hub and the goal is to have a dive into the model to show transformer fundamentals.\n",
    "\n",
    "### Sources\n",
    "\n",
    "* [Attention Is All You Need](https://arxiv.org/abs/1706.03762)\n",
    "* [The Annotated Transformer](https://nlp.seas.harvard.edu/2018/04/03/attention.html)\n",
    "* [The Illustrated Transformer](https://jalammar.github.io/illustrated-transformer/)\n",
    "\n",
    "\n",
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\kzaja\\Documents\\Research\\Github\\reconstructing-transformer\\.venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "import torch\n",
    "import seaborn as sns\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure dependencies are installed, it is recommended to use GPU for this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install sentencepiece -q\n",
    "# !pip install transformers -q"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use parameters from *Helsinki-NLP* available at [https://huggingface.co/Helsinki-NLP/opus-mt-de-en](https://huggingface.co/Helsinki-NLP/opus-mt-de-en)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\kzaja\\Documents\\Research\\Github\\reconstructing-transformer\\.venv\\lib\\site-packages\\transformers\\models\\marian\\tokenization_marian.py:194: UserWarning: Recommended: pip install sacremoses.\n",
      "  warnings.warn(\"Recommended: pip install sacremoses.\")\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"Helsinki-NLP/opus-mt-de-en\")\n",
    "transformer = AutoModelForSeq2SeqLM.from_pretrained(\"Helsinki-NLP/opus-mt-de-en\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon May 29 20:55:31 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 528.79       Driver Version: 528.79       CUDA Version: 12.0     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name            TCC/WDDM | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA GeForce ... WDDM  | 00000000:01:00.0 Off |                  N/A |\n",
      "| N/A   64C    P0    17W /  50W |      0MiB /  4096MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transformer = transformer.cuda()  # send to GPU\n",
    "transformer = transformer.eval()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenization\n",
    "\n",
    "For machine translation the input is a sentence in source language (denoted `src`), for this model the source language is German. The output should be the same sentence, but translated to English, which is called target language (denoted `tgt`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = [\n",
    "    \"Die Maschine ist auf dem Weg nach Hause.\",  # source text\n",
    "]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To allow model to process the text, it needs to be converted into numbers, this process is called tokenization, where each word-piece is assigned a unique number. The tokenization is done using `tokenizers` library, which is a fast Rust library for tokenization. Word-piece is a part of a word, for example, suffix such as *ing* is a unique word piece, since it carries the information about what tense is used (in English). To allow the model to learn to *understand* such texts, it needs to *see* such suffixes as different words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  55, 7618,   29,   37,   57,  995,   96, 2427,    3,    0]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = tokenizer(text, return_tensors=\"pt\", padding=False)\n",
    "tokens[\"input_ids\"]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`tokenizer` has unique index for both languages, German and English. Vocabulary size, which is the number of unique tokens known to the model is 58101."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word-piece: '.' -> token ids: tensor([[17,  3,  0]])\n",
      "Word-piece: '?' -> token ids: tensor([[17, 31,  0]])\n",
      "Word-piece: 'Die' -> token ids: tensor([[55,  0]])\n",
      "Word-piece: 'ist' -> token ids: tensor([[29,  0]])\n",
      "Word-piece: 'Hause' -> token ids: tensor([[2427,    0]])\n",
      "Word-piece: '' -> token ids: tensor([[0]])\n",
      "Word-piece: 'home' -> token ids: tensor([[   17, 12550,     0]])\n",
      "Word-piece: 'is' -> token ids: tensor([[19,  0]])\n",
      "Word-piece: 'machine' -> token ids: tensor([[13799,  1027,     0]])\n",
      "Word-piece: 'translating' -> token ids: tensor([[3388, 6860,   79,    0]])\n"
     ]
    }
   ],
   "source": [
    "for example in [\".\", \"?\", \"Die\", \"ist\", \"Hause\", \"\", \"home\", \"is\", \"machine\", \"translating\"]:\n",
    "    example_tokens = tokenizer([example], return_tensors=\"pt\", padding=False)[\"input_ids\"]\n",
    "    print(f\"Word-piece: '{example}' -> token ids: {example_tokens}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It can also decode tokens back to text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token ids: tensor([[17,  3,  0]]) -> word-piece: .</s>\n",
      "Token ids: tensor([[17]]) -> word-piece: \n",
      "Token ids: tensor([[0]]) -> word-piece: </s>\n",
      "Token ids: tensor([[13799]]) -> word-piece: ▁mach\n",
      "Token ids: tensor([[3388, 6860,   79]]) -> word-piece: translating\n"
     ]
    }
   ],
   "source": [
    "for example in [[17, 3, 0], [17], [0], [13799], [3388, 6860, 79]]:\n",
    "    example_tokens = torch.tensor(example).unsqueeze(0)\n",
    "    print(f\"Token ids: {example_tokens} -> word-piece: {tokenizer.decode(example_tokens[0])}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To read more on tokenizers, following resources might be useful:\n",
    "* [HuggingFace Tokenizer Summary](https://huggingface.co/docs/transformers/tokenizer_summary)\n",
    "* [SentencePiece Paper](https://arxiv.org/abs/1808.06226)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model\n",
    "\n",
    "Model consists of 4 elements:\n",
    "* Embedding - trainable lookup table that maps the numbers to vectors of fixed size, shared between encoder and decoder\n",
    "* Encoder - stack of N identical transformer encoder layers\n",
    "* Decoder - stack of N identical transformer decoder layers\n",
    "* Head - final linear layer with softmax activation function converting dense embeddings to predictions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Translation\n",
    "\n",
    "The whole model is trained on translation problem, which means it's goal it to covert German text to English text. The main entrypoint is `generate` method, which calls the model multiple times using autoregressive predictions to generate the translation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<pad> Machine learning is great</s>'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = [\"Maschinelles Lernen ist großartig\"]\n",
    "tokens = tokenizer(text, return_tensors=\"pt\", padding=False)\n",
    "\n",
    "outputs = transformer.generate(**tokens, max_new_tokens=100)  # using **tokens is shorthand for passing tokens and attention mask\n",
    "tokenizer.decode(outputs[0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: Source code and documentation of `generate` function are implemented by `GeneratorMixin` from HuggingFace, not by the model itself. \n",
    "\n",
    "Generation settings are controlled by the config, which by default is read from model files (they can be usually accessed on HuggingFace hub). For this model generation config looks as follows:\n",
    "\n",
    "```json\n",
    "{\n",
    "  \"_from_model_config\": true,\n",
    "  \"bad_words_ids\": [\n",
    "    [\n",
    "      58100\n",
    "    ]\n",
    "  ],\n",
    "  \"bos_token_id\": 0,\n",
    "  \"decoder_start_token_id\": 58100,\n",
    "  \"eos_token_id\": 0,\n",
    "  \"forced_eos_token_id\": 0,\n",
    "  \"max_length\": 512,\n",
    "  \"num_beams\": 4,\n",
    "  \"pad_token_id\": 58100,\n",
    "  \"transformers_version\": \"4.27.0.dev0\"\n",
    "}\n",
    "```\n",
    "\n",
    "Fore more details go to following resources:\n",
    "* [HuggingFace `GeneratorMixin` documentation](https://huggingface.co/docs/transformers/main_classes/text_generation)\n",
    "* [HuggingFace Text Generation Strategies](https://huggingface.co/docs/transformers/v4.29.1/en/generation_strategies)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model will run beam search decoding, which can be seen from the `num_beams` parameter, which is not 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['last_hidden_state', 'past_key_values', 'encoder_last_hidden_state'])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = [\"Maschinelles Lernen ist großartig\"]\n",
    "tokens = tokenizer(text, return_tensors=\"pt\", padding=False)\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = transformer.model(\n",
    "        input_ids=tokens[\"input_ids\"],\n",
    "        attention_mask=tokens[\"attention_mask\"],\n",
    "        # value 58100 is the token id from config for decoder_start_token_id\n",
    "        decoder_input_ids=torch.Tensor([58100]).long().unsqueeze(0),  # type cast to long and add batch dimension\n",
    "    )\n",
    "\n",
    "outputs.keys()  # outputs is ordered dict overload class"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Last hidden state is decoder prediction, it contains the same number of sequence elements as decoder inputs, but the content is embedding. From this embedding, with the same size as model dimension output word can be predicted by linear layer with softmax activation function, which is the last trained layer of the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 512])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs[\"last_hidden_state\"].shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prediction of the language modelling head is the probability distribution over entire vocabulary. The word with the highest probability is the prediction of the model (in case of greedy decoding)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 58101])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    predictions = transformer.lm_head(outputs[\"last_hidden_state\"])\n",
    "    predictions = torch.nn.functional.softmax(predictions, dim=-1)\n",
    "    \n",
    "predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions.sum(dim=-1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Selecting top 10 results and their probabilities can be done using `torch.topk`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.return_types.topk(\n",
       "values=tensor([7.9567e-01, 1.4070e-02, 1.0553e-02, 6.0083e-03, 3.6412e-03, 3.0484e-03,\n",
       "        1.0981e-03, 9.8738e-04, 9.6284e-04, 7.3160e-04]),\n",
       "indices=tensor([ 8853, 33856,  2004, 16984,  6188,  6989,  6232,  6666,  3234, 33590]))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = torch.topk(predictions.squeeze(0).squeeze(0), k=10, dim=-1)\n",
    "response"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For translating a single word, the outputs are usually not meaningful, since the model needs to see the whole sentence to understand the context. This is the reason, why methods like beam search are used, which allow to generate multiple results and select the best one.\n",
    "\n",
    "Beam search in transformer mode. lt works by exploring the most likely options down to a certain beam size, which is a hyperparameter that determines the number of paths to explore. The algorithm calculates the score of each option by calculating the probability of a token given everything that comes before it. In the transformer architecture, the output is the entire probability for each word in the vocabulary, for each position in the sequence.\n",
    "\n",
    "*Note*: Default `topk` value is 50, which means that the model will generate 50 results and select the best one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Machine\n",
      "Mechanical\n",
      "machine\n",
      "Learning\n",
      "Mach\n",
      "Engineering\n",
      "Learn\n",
      "maschine\n",
      "Maschinen\n",
      "Machines\n"
     ]
    }
   ],
   "source": [
    "for item in response.indices.tolist():\n",
    "    print(tokenizer.decode(item))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prediction word at further position, requires passing not only source language, but also the previously predicted words. This is called autoregressive generation, since the model generates the output one word at a time using its own predictions. In beam search this step is performed more than once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = [\"Maschinelles Lernen ist großartig\"]\n",
    "tokens = tokenizer(text, return_tensors=\"pt\", padding=False)\n",
    "simulated_decoder_predictions = tokenizer(\"<pad> Machine learning is <pad>\", return_tensors=\"pt\", padding=False)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To perform translation, model needs multiple attention masks, which are used to mask out the padding tokens. This is done to prevent the model from paying attention to the padding tokens, which are not part of the input sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['input_ids', 'encoder_outputs', 'past_key_values', 'decoder_input_ids', 'attention_mask', 'head_mask', 'decoder_head_mask', 'cross_attn_head_mask', 'use_cache'])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generation_inputs = transformer.prepare_inputs_for_generation(decoder_input_ids=simulated_decoder_predictions[\"input_ids\"])\n",
    "generation_inputs.keys()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Masking is done using `torch.triu` function, which returns the upper triangular part of a matrix (2D tensor). The upper triangular part of the matrix is used, since the model is autoregressive, which means that it can only see the previous words, not the future ones. \n",
    "\n",
    "Passing very large negative values to the softmax function will result in very small values, which will be rounded to 0. This is used to mask out the padding tokens, since the model will not pay attention to them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "attn = 10 * torch.rand(10, 10)\n",
    "mask = torch.triu(attn)\n",
    "\n",
    "output = torch.nn.functional.softmax(mask * attn, dim=-1)\n",
    "_ = sns.heatmap(output.numpy())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embedding(58101, 512, padding_idx=58100)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformer.model.shared"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Output shape is `(batch_size, sequence_length, hidden_size)`, where `hidden_size` is the size of the embedding vector, 512 for this model. Each embedding represents a point in high-dimensional space, where similar words are closer to each other. Embeddings are trained during the training process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 6, 512])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    embedding = transformer.model.shared(tokenizer(\"Hello world!\", return_tensors=\"pt\", padding=False)[\"input_ids\"])\n",
    "\n",
    "embedding.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encoder\n",
    "\n",
    "Encoder is a stack of TransformerLayers, which are identical. Each layer has 2 sublayers:\n",
    "* Multi-head self-attention mechanism\n",
    "* Position-wise fully connected feed-forward network\n",
    "\n",
    "Encoder blocks are connected to each other, so input to $N$-th block is the output of $(N-1)$-th block."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MarianEncoder(\n",
       "  (embed_tokens): Embedding(58101, 512, padding_idx=58100)\n",
       "  (embed_positions): MarianSinusoidalPositionalEmbedding(512, 512)\n",
       "  (layers): ModuleList(\n",
       "    (0-5): 6 x MarianEncoderLayer(\n",
       "      (self_attn): MarianAttention(\n",
       "        (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "      )\n",
       "      (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      (activation_fn): SiLUActivation()\n",
       "      (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "      (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "      (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformer.model.encoder"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Positional embedding, which is added to the input embeddings at the bottom of the encoder, is used to provide information about the position of each token in the sequence. This is needed because the model does not contain any recurrent or convolutional layers, so it does not know the order of the tokens.\n",
    "\n",
    "For this model, the positional embedding is a vector of size 512 (model dimension) and length 512 (max sequence length of the model), which is added to the input embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([512, 512])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = tokenizer(\"Hello world!\", return_tensors=\"pt\", padding=False)[\"input_ids\"]\n",
    "position_encoding = transformer.model.encoder.embed_positions(input_ids_shape=[100, 512])\n",
    "position_encoding.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Positional encoding is simply added to the embedding, which creates input of encoder block."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 6, 512])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = embedding + position_encoding[:embedding.shape[1], :]\n",
    "inputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ModuleList(\n",
       "  (0-5): 6 x MarianEncoderLayer(\n",
       "    (self_attn): MarianAttention(\n",
       "      (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "      (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "      (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "      (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "    )\n",
       "    (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "    (activation_fn): SiLUActivation()\n",
       "    (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "    (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "    (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformer.model.encoder.layers"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This class uses iterable `torch.ModuleList`, so to pass the inputs through all encoder blocks, it is enough to iterate over the list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 6, 512])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    for layer in transformer.model.encoder.layers:\n",
    "        # attention mask in encoder is used to prevent attending to padding tokens\n",
    "        encoder_outputs = layer(inputs, attention_mask=None, layer_head_mask=None)\n",
    "\n",
    "encoder_outputs[0].shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encoder Block\n",
    "\n",
    "Inside each encoder block the same operations are performed, the only difference is the parameters inside trained matrices. The two operations are self-attention and feed-forward network.\n",
    "\n",
    "### Self-Attention\n",
    "\n",
    "Self-attention is a mechanism that allows the model to learn the dependencies between words in a sequence. It is called self-attention because the attention mechanism is applied to the sequence itself, instead of comparing it to another sequence."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Key projection is a linear layer with learned parameters computing keys from inputs. Keys are abstract representation of the inputs, which are used to compute the attention scores. The intuition behind the content of keys is that they represent the information, which given input should exposes, depending on the context.\n",
    "\n",
    "For example in the sentence: *I like machine learning, because it is useful and fun to learn*, during encoding the word *it* refers to *machine learning*, so it should be exposed by key projection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=512, out_features=512, bias=True)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformer.model.encoder.layers[0].self_attn.k_proj"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The layer can have bias and it needs to preserve the model dimensionality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 6, 512])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    keys = transformer.model.encoder.layers[0].self_attn.k_proj(inputs)\n",
    "\n",
    "keys.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Query is another abstract representation used for computing attention scores, which is computed using linear layer with learned parameters. The intuition behind the content of queries is that they represent the information, which given input should pay attention to, depending on the context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=512, out_features=512, bias=True)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformer.model.encoder.layers[0].self_attn.q_proj"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shape of queries is the same as keys."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 6, 512])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    query = transformer.model.encoder.layers[0].self_attn.q_proj(inputs)\n",
    "\n",
    "query.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Values are third abstraction, which represents the information given input vector carries. They are also computed using linear layer with learned parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 6, 512])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    values = transformer.model.encoder.layers[0].self_attn.v_proj(inputs)\n",
    "\n",
    "values.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Attention weights (sometimes called attention scores) represent the strength of relation between each pair of tokens. They are computed by multiplying queries and keys and then normalizing them using softmax function, so the sum of weights for each token is 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 6, 6])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    attn_weights = query @ keys.transpose(1, 2)\n",
    "    attn_weights = torch.nn.functional.softmax(attn_weights, dim=-1)\n",
    "\n",
    "attn_weights.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally values are multiplied by attention weights to get the context vector, which is the output of self-attention layer containing information about relation between tokens. This is the reason why transformer is able to learn richer dependencies between elements in the sentence, since each token is connected to each other token and the strength of those connections is learned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 6, 512])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs = attn_weights @ values\n",
    "outputs.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi-Head Attention\n",
    "\n",
    "Self-attention described above computes only single context vector of attention scores, which for real problems is often not enough. Multi-head attention is a mechanism, which uses multiple independent (or learnable) key, query and value matrices to capture different relations between tokens. This is similar to using multiple independent convolutional filters in a single layer in conv net. However, attention needs to preserve the shape of input representation, so before output is generated all different context vectors are concatenated and multiplied by another learned matrix converting the shape back to input shape. This matrix is called output projection matrix (it is also learned!). \n",
    "\n",
    "Usually more heads means better modelling abilities, the model used in this example has 8 heads."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformer.model.encoder.layers[0].self_attn.num_heads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=512, out_features=512, bias=True)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformer.model.encoder.layers[0].self_attn.out_proj"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Note*: Real transformer uses more efficient batch-matrix multiplication of above operations. Also all heads are stacked into matrices, which makes computing keys and queries more efficient. The key and query dimension is `model_dimension / num_heads`, so for this model it is 64."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feedforward Network\n",
    "\n",
    "This part of the transformer is a simple feedforward network with 2 linear layers and nonlinear activation function. It is applied to each token independently, so it does not change the shape of the input. In most implementations first layer is an up-projection in dimension and second is down-projection. For this model, the hidden dimension is 2048 and the output dimension is 512, which is the model dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=512, out_features=2048, bias=True)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformer.model.encoder.layers[0].fc1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=2048, out_features=512, bias=True)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformer.model.encoder.layers[0].fc2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The activation in the model is performed between feedforward layers, in this case SiLU is used, but ReLU and GeLU (and other variants of derived from piecewise linear functions) are also used often."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = torch.linspace(-10, 10, 100)\n",
    "\n",
    "_ = plt.plot(x.numpy(), transformer.model.encoder.layers[0].activation_fn(x).numpy())\n",
    "_ = plt.title(\"SiLU Activation Function\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Residual Connection\n",
    "\n",
    "After each layer with trained parameters, residual connection is added, which means that inputs to the layer and added to its outputs, which makes the gradient flow more stable, allowing the model have more layers."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalization and Dropout\n",
    "\n",
    "Additionally, each layer implements regularization with dropout (removing random portion of features) and normalization (scaling the features to have mean 0 and variance 1). The normalization is called layer normalization, since it is applied to each token independently. For more details see torch documentation about those layers:\n",
    "* [Dropout](https://pytorch.org/docs/stable/generated/torch.nn.Dropout.html)\n",
    "* [LayerNorm](https://pytorch.org/docs/stable/generated/torch.nn.LayerNorm.html)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decoder Block\n",
    "\n",
    "Decoder block is very similar to encoder block, but it contains one additional attention mechanism. It consists of 3 sublayers:\n",
    "* Masked multi-head self-attention - the same as in encoder block, but with masking out the future tokens\n",
    "* Multi-head cross-attention - attention block computing relations between source language and target language tokens\n",
    "* Feed-forward network - the same as in encoder block "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MarianDecoder(\n",
       "  (embed_tokens): Embedding(58101, 512, padding_idx=58100)\n",
       "  (embed_positions): MarianSinusoidalPositionalEmbedding(512, 512)\n",
       "  (layers): ModuleList(\n",
       "    (0-5): 6 x MarianDecoderLayer(\n",
       "      (self_attn): MarianAttention(\n",
       "        (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "      )\n",
       "      (activation_fn): SiLUActivation()\n",
       "      (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      (encoder_attn): MarianAttention(\n",
       "        (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "      )\n",
       "      (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "      (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "      (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformer.model.decoder"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cross-attention is a trainable module with three 4 parameter matrices, which are very similar to self-attention. The only difference is, where the inputs come from. In the decoder cross-attention queries are computed from the previous decoder block, while keys and values are computed from the encoder block. This allows the decoder to pay attention to the source language tokens, while generating the target language tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MarianAttention(\n",
       "  (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "  (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "  (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "  (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformer.model.decoder.layers[0].encoder_attn"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# All Together\n",
    "\n",
    "Transformer is quite complex model, but the fundamental idea of removing recurrence and replacing it with attention allowed the model to achieve spectacular results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate(text, max_new_tokens=100):\n",
    "    tokens = tokenizer(text, return_tensors=\"pt\", padding=False)\n",
    "    outputs = transformer.generate(**tokens, max_new_tokens=max_new_tokens)\n",
    "    predictions = tokenizer.decode(outputs[0])\n",
    "\n",
    "    return re.sub(\"<pad>|</s>\", \"\", predictions).strip()  # naive post-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Machine learning is great'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translate(\"Maschinelles Lernen ist großartig\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
