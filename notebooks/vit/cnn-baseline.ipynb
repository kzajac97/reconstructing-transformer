{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Baseline\n",
    "\n",
    "This notebook contains code for training baseline convolutional model, to compare to ViT model. The performance of baseline is better, than ViT, since the dataset is not suited for such large models, it only serves as learning example. \n",
    "\n",
    "### Setup"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import math\n",
    "import os\n",
    "from functools import cached_property\n",
    "from typing import Any, Callable, Iterable, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torchvision\n",
    "import lovely_tensors as lt\n",
    "import wandb\n",
    "from skimage import io\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "lt.monkey_patch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.ToTensor(),  # convert PIL to tensor\n",
    "    torchvision.transforms.Lambda(lambda image: image.squeeze()),  # convert shape from (BATCH_SIZE, 1, X, Y) to (BATCH_SIZE, X * Y)\n",
    "])\n",
    "\n",
    "train_dataset = torchvision.datasets.MNIST(\"../data\", download=True, transform=transforms, train=True)\n",
    "test_dataset = torchvision.datasets.MNIST(\"../data\", download=True, transform=transforms, train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=128, shuffle=True)\n",
    "test_data_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=128, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Model\n",
    "\n",
    "The baseline is convolutional model with 2 conv layers."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNISTClassifier(torch.nn.Module):\n",
    "    \"\"\"Convolutional classifier as a simple baseline model for image classification.\"\"\"\n",
    "\n",
    "    def __init__(self, num_classes: int):\n",
    "        \"\"\"\n",
    "        :param num_classes: number of classes in the dataset\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        self.num_classes = num_classes\n",
    "        self.stack = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(1, 32, kernel_size=3, stride=1),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Conv2d(32, 64, kernel_size=3, stride=1),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.MaxPool2d(kernel_size=2),\n",
    "            torch.nn.Flatten(),\n",
    "            torch.nn.Linear(9216, 128),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(128, num_classes),\n",
    "            torch.nn.Softmax(dim=1),\n",
    "        )\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        return self.stack(x.unsqueeze(1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create instance of the model and run it on sample batch of 128 examples\n",
    "model = MNISTClassifier(num_classes=10).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 28, 28])\n",
      "torch.Size([128])\n"
     ]
    }
   ],
   "source": [
    "for x, y in train_data_loader:\n",
    "    print(x.shape)\n",
    "    print(y.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([128, 10]), tensor cuda:0 1.000)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    y = model(x.cuda())  # x exists from previous cell\n",
    "\n",
    "# make sure shape is correct and all outputs sum to 1 (probabilities after softmax)\n",
    "y.shape, y[0].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Evaluation\n",
    "\n",
    "Create eval loop first, to make sure model behaves as expected."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model: torch.nn.Module, data_loader: Iterable) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "    \"\"\"\n",
    "    Prediction loop for the given model and data loader\n",
    "    :note: assumes running on CUDA enabled device\n",
    "    \"\"\"\n",
    "    model = model.eval()\n",
    "    targets, predictions = [], []\n",
    "\n",
    "    for inputs, y_true in data_loader:\n",
    "        with torch.no_grad():\n",
    "            inputs = inputs.cuda()\n",
    "            y_true = y_true.cuda()\n",
    "\n",
    "            y_pred = model(inputs)\n",
    "\n",
    "            predictions.append(y_pred)\n",
    "            targets.append(y_true)\n",
    "\n",
    "    return torch.cat(targets), torch.cat(predictions)\n",
    "\n",
    "\n",
    "def evaluate(y_true: Iterable, y_pred: Iterable) -> dict[str, float]:\n",
    "    return {\n",
    "        \"accuracy\": metrics.accuracy_score(y_true, y_pred),\n",
    "        \"precision\": metrics.precision_score(y_true, y_pred, zero_division=0, average=\"macro\"),\n",
    "        \"recall\": metrics.recall_score(y_true, y_pred, zero_division=0, average=\"macro\"),\n",
    "        \"f1_score\": metrics.f1_score(y_true, y_pred, zero_division=0, average=\"macro\"),\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_training_progress(model: torch.nn.Module, epoch: int, data_loader: Iterable) -> None:\n",
    "    \"\"\"\n",
    "    Logs progress of the model training to W&B\n",
    "    :note: requires Wto be called inside W&B run\n",
    "    \"\"\"\n",
    "    logs = {}\n",
    "    targets, predictions = predict(model, data_loader)\n",
    "\n",
    "    logs[\"accuracy\"] = metrics.accuracy_score(targets.cpu(), predictions.cpu().argmax(dim=-1))\n",
    "    logs[\"f1_score\"] = metrics.f1_score(\n",
    "        targets.cpu(), predictions.cpu().argmax(dim=-1), zero_division=0, average=\"macro\"\n",
    "    )\n",
    "\n",
    "    wandb.log(logs, step=epoch)\n",
    "\n",
    "\n",
    "def count_trainable_parameters(model: torch.nn.Module) -> int:\n",
    "    \"\"\"Return the number of trainable parameters in neural model\"\"\"\n",
    "    return sum(param.numel() for param in model.parameters() if param.requires_grad)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Run the model on entire test dataset and compute metrics. Without training they will be random, so around 10% accuracy can be expdcted."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([10000]), torch.Size([10000, 10]))"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets, predictions = predict(model, test_data_loader)\n",
    "targets.shape, predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.06      0.26      0.09       980\n",
      "           1       0.01      0.04      0.01      1135\n",
      "           2       0.00      0.00      0.00      1032\n",
      "           3       0.00      0.00      0.00      1010\n",
      "           4       0.00      0.00      0.00       982\n",
      "           5       0.00      0.00      0.00       892\n",
      "           6       0.00      0.00      0.00       958\n",
      "           7       0.00      0.00      0.00      1028\n",
      "           8       0.00      0.00      0.00       974\n",
      "           9       0.00      0.00      0.00      1009\n",
      "\n",
      "    accuracy                           0.03     10000\n",
      "   macro avg       0.01      0.03      0.01     10000\n",
      "weighted avg       0.01      0.03      0.01     10000\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(targets.cpu(), predictions.cpu().argmax(dim=-1), zero_division=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Train\n",
    "\n",
    "Define training loop and logging to W&B"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split_data_loader(dataset, test_size: float = 0.1):\n",
    "    \"\"\"Train test split function similar to sklearn applied to torch DataLoaders\"\"\"\n",
    "\n",
    "    train_indices, validation_indices = train_test_split(range(len(dataset)), test_size=test_size, random_state=42)\n",
    "    \n",
    "    train_dataset = torch.utils.data.Subset(dataset, train_indices)\n",
    "    validation_dataset = torch.utils.data.Subset(dataset, validation_indices)\n",
    "    \n",
    "    train_data_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=128, shuffle=True)\n",
    "    validation_data_loader = torch.utils.data.DataLoader(dataset=validation_dataset, batch_size=128, shuffle=False)\n",
    "    \n",
    "    return train_data_loader, validation_data_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(\n",
    "    model: torch.nn.Module,\n",
    "    optimizer: torch.optim.Optimizer,\n",
    "    loss_function: Callable,\n",
    "    dataset: Iterable,\n",
    "    n_epochs: int,\n",
    "    validation_size: float = 0.1,\n",
    ") -> torch.nn.Module:\n",
    "    \"\"\"\n",
    "    Train loop for the given torch model\n",
    "    :note: assumes running on CUDA enabled device\n",
    "    \"\"\"\n",
    "    train_data_loader, validation_data_loader = train_test_split_data_loader(dataset, test_size=validation_size)\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        for x, y in train_data_loader:\n",
    "            model = model.train()\n",
    "            x = x.cuda()\n",
    "            y = y.cuda()\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            y_pred = model(x)\n",
    "\n",
    "            loss_value = loss_function(y_pred, y)\n",
    "            loss_value.backward()\n",
    "            optimizer.step()\n",
    "       \n",
    "        log_training_progress(model, epoch, validation_data_loader)\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def run(\n",
    "    model: torch.nn.Module,\n",
    "    optimizer: torch.optim.Optimizer,\n",
    "    loss_function: Callable,\n",
    "    train_dataset: Iterable,\n",
    "    test_dataset: Iterable,\n",
    "    n_epochs: int,\n",
    "    config: dict[str, Any],\n",
    "    validation_size=0.1,\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Run training and evaluation loop for the given model and data\n",
    "\n",
    "    :param model: pytorch model to train\n",
    "    :param optimizer: pytorch optimizer to use\n",
    "    :param loss_function: pytorch loss function to use\n",
    "    :param train_dataset: iterable dataset for training\n",
    "    :param test_dataset: iterable dataset for testing\n",
    "    :param n_epochs: number of epochs to train\n",
    "    :param config: dictionary with configuration for W&B\n",
    "    :param validation_size: size of the validation set\n",
    "    \"\"\"\n",
    "    with wandb.init(project=config[\"project_name\"], name=config[\"run_name\"]):\n",
    "        wandb.log(config)\n",
    "        test_data_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=128, shuffle=False)\n",
    "        # run training and evaluation\n",
    "        model = train(model, optimizer, loss_function, train_dataset, n_epochs, validation_size)\n",
    "        targets, predictions = predict(model, test_data_loader)\n",
    "        # log metrics and model info to W&B\n",
    "        wandb.log(evaluate(targets.cpu(), predictions.cpu().argmax(dim=-1)))\n",
    "        wandb.log({\"n_trainable_parameters\": count_trainable_parameters(model)})\n",
    "        # save model to file and upload to W&B\n",
    "        path = os.path.join(wandb.run.dir, \"model.pt\")\n",
    "        torch.save(model.state_dict(), path)\n",
    "        torch.save(model.state_dict(), \"model.pt\")\n",
    "        wandb.save(path)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Run\n",
    "\n",
    "Run with W&B logging, training metrics and evaluation of the trained model on test dataset will appear in the interface and the logs in this notebook."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "loss_function = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "config = {\n",
    "    \"project_name\": \"vision-transformer\",  # W&B config\n",
    "    \"run_name\": \"cnn-baseline\",  # W&B config\n",
    "    \"dataset\": \"MNIST\",\n",
    "    \"model\": \"FeedForward\",\n",
    "    \"optimizer\": \"AdamW\",\n",
    "    \"loss_function\": \"CrossEntropyLoss\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "wandb version 0.15.5 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.10"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/workspace/wandb/run-20230707_210635-u9qphmqs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/kzajac/vision-transformer/runs/u9qphmqs' target=\"_blank\">cnn-baseline</a></strong> to <a href='https://wandb.ai/kzajac/vision-transformer' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/kzajac/vision-transformer' target=\"_blank\">https://wandb.ai/kzajac/vision-transformer</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/kzajac/vision-transformer/runs/u9qphmqs' target=\"_blank\">https://wandb.ai/kzajac/vision-transformer/runs/u9qphmqs</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mwandb\u001B[0m: \u001B[33mWARNING\u001B[0m Saving files without folders. If you want to preserve sub directories pass base_path to wandb.save, i.e. wandb.save(\"/mnt/folder/file.h5\", base_path=\"/mnt\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁▅▆▆▆▆▇▇▇▆▇▇▇▇▇▇▇█▇█▆██▇██▇▆▇</td></tr><tr><td>f1_score</td><td>▁▅▆▆▆▆▇▇▇▆▇▇▇▇▇▇▇█▇█▆██▇██▇▆▇</td></tr><tr><td>n_trainable_parameters</td><td>▁</td></tr><tr><td>precision</td><td>▁</td></tr><tr><td>recall</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.9894</td></tr><tr><td>dataset</td><td>MNIST</td></tr><tr><td>f1_score</td><td>0.98935</td></tr><tr><td>loss_function</td><td>CrossEntropyLoss</td></tr><tr><td>model</td><td>FeedForward</td></tr><tr><td>n_trainable_parameters</td><td>1199882</td></tr><tr><td>optimizer</td><td>AdamW</td></tr><tr><td>precision</td><td>0.9895</td></tr><tr><td>project_name</td><td>vision-transformer</td></tr><tr><td>recall</td><td>0.98923</td></tr><tr><td>run_name</td><td>cnn-baseline</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">cnn-baseline</strong> at: <a href='https://wandb.ai/kzajac/vision-transformer/runs/u9qphmqs' target=\"_blank\">https://wandb.ai/kzajac/vision-transformer/runs/u9qphmqs</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230707_210635-u9qphmqs/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trained_transformer = run(\n",
    "    model,\n",
    "    optimizer,\n",
    "    loss_function,\n",
    "    train_dataset,\n",
    "    test_dataset,\n",
    "    n_epochs=30,\n",
    "    config=config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
